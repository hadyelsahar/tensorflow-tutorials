{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A TensorFlow Seq2Seq [Building model]\n",
    "\n",
    "for compitability with tensorflow v1.2 the code is adapted from the code \n",
    "https://github.com/JayParks/tf-seq2seq/blob/master/seq2seq_model.py\n",
    "\n",
    "The model contains the following modules \n",
    "- Sequence to sequence model\n",
    "- Encoder is multilayer GRU\n",
    "- Decoder is a multilayer GRU\n",
    "\n",
    "Until this part the model is only trainable with simple print of loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the RNN-encoder-decoder code easy to understand we assume the following \n",
    "\n",
    "- all additional characters such as `<unk> <rare> <pad>` are added to the vocabulary \n",
    "- vocabulary is created offline \n",
    "- The inputs to the decoder are NOT preprocessed beforehand to start with  `<s>` and  `<\\s>`\n",
    "- `<s>` and  `<\\s>` are stored in config.DECODER_START_TOKEN_ID and config.DECODER_END_TOKEN_ID and added on the fly in the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class config():\n",
    "    NUM_LAYERS = 3\n",
    "    HIDDEN_SIZE = 256\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    LR = 0.5\n",
    "    MAX_GRAD_NORM = 5.0\n",
    "    ATTENTION_SIZE = 30\n",
    "    NUM_SAMPLES = 512\n",
    "    \n",
    "    ENC_VOCAB = 300\n",
    "    DEC_VOCAB = 900\n",
    "\n",
    "    DECODER_START_TOKEN_ID = 2\n",
    "    DECODER_END_TOKEN_ID = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq():\n",
    "\n",
    "    def __init__(self, mode='training'):\n",
    "        print('Initializing new seq 2 seq model')\n",
    "\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        self.__create_placeholders()\n",
    "        self.__create_encoder()\n",
    "        self.__create_decoder()\n",
    "        self.__create_loss()\n",
    "        self.__create_optimizer()\n",
    "\n",
    "    def __create_placeholders(self):\n",
    "\n",
    "        # encoder_inputs : size [batch_size, max_step_size]\n",
    "        self.encoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"encoder_inputs\")\n",
    "        \n",
    "        # encoder_inputs_length: [batch_size]\n",
    "        self.encoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,), name='encoder_inputs_length')\n",
    "\n",
    "        self.batch_size = tf.shape(self.encoder_inputs)[0]\n",
    "\n",
    "        ## Decoder placeholders:\n",
    "        ## these are the raw inputs to the decoder:\n",
    "        self.decoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"decoder_inputs\")\n",
    "        self.decoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,), name='decoder_inputs_length')\n",
    "\n",
    "        # for training we add <s> start tag for the input of the decoder and </s> end tag for the decoder target\n",
    "        # as shown in figure https://www.tensorflow.org/images/basic_seq2seq.png\n",
    "\n",
    "        starttokens = tf.ones([self.batch_size, 1], dtype=tf.int32) * config.DECODER_START_TOKEN_ID\n",
    "        endtokens = tf.ones([self.batch_size, 1], dtype=tf.int32) * config.DECODER_END_TOKEN_ID\n",
    "\n",
    "        self.decoder_inputs_train = tf.concat([starttokens, self.decoder_inputs], axis=1)\n",
    "        self.decoder_targets_train = tf.concat([self.decoder_inputs, endtokens], axis=1)\n",
    "\n",
    "        # decoder_inputs_length_train: [batch_size]\n",
    "        # both input and target to the decoder are of the same length\n",
    "        self.decoder_inputs_length_train = self.decoder_inputs_length + 1\n",
    "        self.decoder_targets_length_train = self.decoder_inputs_length + 1\n",
    "        # calculating max_decoder_length\n",
    "        self.decoder_max_length = tf.reduce_max(self.decoder_inputs_length_train)\n",
    "\n",
    "\n",
    "        # global step\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "\n",
    "    def __build_sample_softmax(self):\n",
    "        \n",
    "        if 0 < config.NUM_SAMPLES < config.DEC_VOCAB:\n",
    "\n",
    "            w = tf.get_variable(\"proj_w\", shape=[config.HIDDEN_SIZE, config.DEC_VOCAB])\n",
    "            b = tf.get_variable(\"proj_b\", shape=[config.DEC_VOCAB])\n",
    "            self.output_projection = (w, b)\n",
    "\n",
    "        def sampled_loss(inputs, labels):\n",
    "            labels = tf.reshape(labels, [-1, 1])\n",
    "            return tf.nn.sampled_softmax_loss(tf.transpose(w), b, inputs, labels,\n",
    "                                              config.NUM_SAMPLES, config.DEC_VOCAB)\n",
    "\n",
    "        self.softmax_loss_function = sampled_loss\n",
    "\n",
    "    def __create_encoder(self):\n",
    "        print('building encoder ...')\n",
    "        start = time.time()\n",
    "\n",
    "        with tf.variable_scope('encoder'):\n",
    "\n",
    "            # Create Embeddings Weights\n",
    "            self.encoder_embeddings = tf.get_variable(\"encoder_embeddings\",\n",
    "                                                      shape=[config.ENC_VOCAB, config.HIDDEN_SIZE],\n",
    "                                                      initializer=self.__helper__initializer(),\n",
    "                                                      dtype=tf.float32\n",
    "                                                      )\n",
    "            # embedding the encoder inputs\n",
    "            encoder_inputs_embedded = tf.nn.embedding_lookup(self.encoder_embeddings, self.encoder_inputs)\n",
    "\n",
    "            # changing the dimensionality of embedded inputs into hidden size\n",
    "            encoder_input_layer = Dense(config.HIDDEN_SIZE, dtype=tf.float32, name='encoder_input_projection')\n",
    "            self.encoder_inputs_embedded = encoder_input_layer(encoder_inputs_embedded)\n",
    "\n",
    "            # create encoder cell\n",
    "            gru = tf.nn.rnn_cell.GRUCell(config.HIDDEN_SIZE)\n",
    "            self.encoder_cell = tf.nn.rnn_cell.MultiRNNCell([gru] * config.NUM_LAYERS)\n",
    "\n",
    "            # Encode input sequences into context vectors:\n",
    "            # encoder_outputs: [batch_size, max_time_step, cell_output_size]\n",
    "            # encoder_state: [batch_size, cell_output_size]\n",
    "            \n",
    "            self.encoder_outputs, self.encoder_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=self.encoder_cell,\n",
    "                inputs=self.encoder_inputs_embedded,\n",
    "                sequence_length=self.encoder_inputs_length,\n",
    "                dtype=tf.float32\n",
    "            )\n",
    "\n",
    "        print('Building encoder in: ', time.time() - start, ' secs')\n",
    "\n",
    "    def __create_decoder(self):\n",
    "        print(\"building decoder and attention ..\")\n",
    "        start = time.time()\n",
    "\n",
    "        with tf.variable_scope('decoder'):\n",
    "\n",
    "            # input and output layers to the decoder\n",
    "            decoder_input_layer = Dense(config.HIDDEN_SIZE, dtype=tf.float32, name='decoder_input_projection')\n",
    "            decoder_output_layer = Dense(config.DEC_VOCAB, name=\"decoder_output_projection\")\n",
    "            self.decoder_initial_state = self.encoder_last_state\n",
    "\n",
    "            # creating decoder embedding weights\n",
    "            self.decoder_embeddings = tf.get_variable(\"decoder_embeddings\",\n",
    "                                                      shape=[config.DEC_VOCAB, config.HIDDEN_SIZE],\n",
    "                                                      initializer=self.__helper__initializer(),\n",
    "                                                      dtype=tf.float32\n",
    "                                                      )\n",
    "\n",
    "            # create decoder cell:\n",
    "            gru = tf.nn.rnn_cell.GRUCell(config.HIDDEN_SIZE)\n",
    "            self.decoder_cell_list = [gru] * config.NUM_LAYERS\n",
    "\n",
    "            self.decoder_cell = tf.nn.rnn_cell.MultiRNNCell(self.decoder_cell_list)\n",
    "\n",
    "            # compose the decoder\n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # changing inputs to embeddings and then through the input projection\n",
    "                # decoder_inputs_embedded: [batch_size, max_time_step + 1, embedding_size]\n",
    "                self.decoder_inputs_embedded = tf.nn.embedding_lookup(params=self.decoder_embeddings, ids=self.decoder_inputs_train)\n",
    "                self.decoder_inputs_embedded = decoder_input_layer(self.decoder_inputs_embedded)\n",
    "\n",
    "                # Helper to feed inputs to the training:\n",
    "\n",
    "                self.training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=self.decoder_inputs_embedded,\n",
    "                    sequence_length=self.decoder_inputs_length_train,\n",
    "                    name='training_helper')\n",
    "\n",
    "                # self.decoder_initial_state = [state for state in self.encoder_last_state]\n",
    "                # self.decoder_initial_state[-1] = self.decoder_cell_list[-1].zero_state(batch_size=tf.shape(self.encoder_inputs)[0], dtype=tf.float32)\n",
    "                self.decoder_initial_state = self.encoder_last_state\n",
    "\n",
    "                # Build the decoder\n",
    "                self.decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=self.decoder_cell,\n",
    "                    helper=self.training_helper,\n",
    "                    initial_state=self.decoder_initial_state,\n",
    "                    output_layer=decoder_output_layer)\n",
    "\n",
    "                self.decoder_outputs, self.decoder_last_state, self.decoder_outputs_length_decode = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder=self.decoder,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=self.decoder_max_length\n",
    "                )\n",
    "\n",
    "        print('Building decoder in: ', time.time() - start, ' secs')\n",
    "\n",
    "    def __create_loss(self):\n",
    "\n",
    "        print('Creating loss...')\n",
    "        start = time.time()\n",
    "\n",
    "        self.decoder_logits = tf.identity(self.decoder_outputs.rnn_output, name=\"decoder_logits\")\n",
    "        self.decoder_pred = tf.argmax(self.decoder_logits, axis=-1, name=\"decoder_pred\")\n",
    "\n",
    "        # masking the sequence in order to calculate the error according to the calculated\n",
    "        mask = tf.sequence_mask(self.decoder_inputs_length_train, maxlen=self.decoder_max_length, dtype=tf.float32, name=\"masks\")\n",
    "\n",
    "        # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "        self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.decoder_logits,\n",
    "                                         targets=self.decoder_targets_train,\n",
    "                                         average_across_timesteps=True,\n",
    "                                         average_across_batch=True,\n",
    "                                         weights=mask,\n",
    "                                         name=\"batch_loss\")\n",
    "\n",
    "        print('Building loss in: ', time.time() - start, ' secs')\n",
    "\n",
    "\n",
    "    def __create_optimizer(self):\n",
    "        print('creating optimizer...')\n",
    "        start = time.time()\n",
    "\n",
    "        self.opt = tf.train.RMSPropOptimizer(learning_rate=config.LR)\n",
    "\n",
    "        # normalize the gradients of a parameter vector when its L2 norm exceeds a certain threshold according to\n",
    "        trainable_params = tf.trainable_variables()\n",
    "        \n",
    "        # calculate gradients of the loss given all the trainable parameters\n",
    "        gradients = tf.gradients(self.loss, trainable_params)\n",
    "        \n",
    "        # Gradient clipping\n",
    "        # new_gradients = gradients * threshold / l2_norm(gradients)\n",
    "        clip_gradients, _ = tf.clip_by_global_norm(gradients, config.MAX_GRAD_NORM)\n",
    "\n",
    "        self.updates = self.opt.apply_gradients(zip(clip_gradients, trainable_params), global_step=self.global_step)\n",
    "\n",
    "\n",
    "        print('Building optimizer in: ', time.time() - start, ' secs')\n",
    "\n",
    "\n",
    "    def __helper__initializer(self):\n",
    "        sqrt3 = math.sqrt(3)  # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "        initializer = tf.random_uniform_initializer(-sqrt3, sqrt3, dtype=tf.float32)\n",
    "        return initializer\n",
    "\n",
    "    def train(self, sess,encoder_inputs, encoder_inputs_length, decoder_inputs, decoder_inputs_lengths):\n",
    "\n",
    "        feed_dict = {\n",
    "            self.encoder_inputs: encoder_inputs,\n",
    "            self.encoder_inputs_length: encoder_inputs_length,\n",
    "            self.decoder_inputs: decoder_inputs,\n",
    "            self.decoder_inputs_length: decoder_inputs_lengths\n",
    "        }\n",
    "        _, loss = sess.run([self.updates, self.loss], feed_dict=feed_dict)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Seq2Seq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "encoder_lengths = [5, 8, 8, 5, 10] * 100\n",
    "decoder_lengths = [5, 8, 8, 5, 10] * 100\n",
    "\n",
    "encoder_inputs = np.zeros((500,10))\n",
    "\n",
    "for c, i in enumerate(encoder_lengths):\n",
    "    encoder_inputs[c,:i] = np.random.randint(0, 300, i)\n",
    "\n",
    "decoder_inputs = np.zeros_like(encoder_inputs)\n",
    "\n",
    "for c, r in enumerate(encoder_inputs):\n",
    "    tmp = deque(r)\n",
    "    tmp.rotate(1)\n",
    "    tmp1 = tmp\n",
    "    tmp.rotate(1)\n",
    "    tmp2 = tmp\n",
    "    tmp.rotate(1)\n",
    "    tmp3 = tmp\n",
    "    decoder_inputs[c] = np.sum([tmp1, tmp2, tmp3], axis=0)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    encoder_inputs = np.array(encoder_inputs)\n",
    "    encoder_lengths = np.array(encoder_lengths)\n",
    "    decoder_inputs = np.array(decoder_inputs)\n",
    "    decoder_lengths = np.array(decoder_lengths)\n",
    "\n",
    "\n",
    "    EPOCHS = 100\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        loss = model.train(sess, encoder_inputs, encoder_lengths, decoder_inputs, decoder_lengths)\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
