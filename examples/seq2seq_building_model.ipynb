{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A TensorFlow Seq2Seq \n",
    "\n",
    "for compitability with tensorflow v1.2 the code is adapted from the code \n",
    "https://github.com/JayParks/tf-seq2seq/blob/master/seq2seq_model.py\n",
    "\n",
    "The model contains the following modules \n",
    "- Sequence to sequence model\n",
    "- Encoder is multilayer GRU\n",
    "- Decoder is a multilayer GRU\n",
    "\n",
    "Until this part the model is only trainable in the next ver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the RNN-encoder-decoder code easy to understand we assume the following \n",
    "\n",
    "- all additional characters such as `<unk> <rare> <pad>` are added to the vocabulary \n",
    "- vocabulary is created offline \n",
    "- The inputs to the decoder are NOT preprocessed beforehand to start with  `<s>` and  `<\\s>`\n",
    "- `<s>` and  `<\\s>` are stored in config.DECODER_START_TOKEN_ID and config.DECODER_END_TOKEN_ID and added on the fly in the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class config():\n",
    "    NUM_LAYERS = 3\n",
    "    HIDDEN_SIZE = 256\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    LR = 0.5\n",
    "    MAX_GRAD_NORM = 5.0\n",
    "    ATTENTION_SIZE = 30\n",
    "    NUM_SAMPLES = 512\n",
    "    \n",
    "    ENC_VOCAB = 300\n",
    "    DEC_VOCAB = 900\n",
    "\n",
    "    DECODER_START_TOKEN_ID = 2\n",
    "    DECODER_END_TOKEN_ID = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq():\n",
    "\n",
    "    def __init__(self, mode='training'):\n",
    "        print('Initializing new seq 2 seq model')\n",
    "\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        self.__create_placeholders()\n",
    "        self.__create_encoder()\n",
    "        self.__create_decoder()\n",
    "        self.__create_loss()\n",
    "        self.__create_optimizer()\n",
    "\n",
    "    def __create_placeholders(self):\n",
    "\n",
    "        # encoder_inputs : size [batch_size, max_step_size]\n",
    "        self.encoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"encoder_inputs\")\n",
    "        \n",
    "        # encoder_inputs_length: [batch_size]\n",
    "        self.encoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,), name='encoder_inputs_length')\n",
    "\n",
    "        self.batch_size = tf.shape(self.encoder_inputs)[0]\n",
    "\n",
    "        ## Decoder placeholders:\n",
    "        ## these are the raw inputs to the decoder:\n",
    "        self.decoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"decoder_inputs\")\n",
    "        self.decoder_inputs_length = tf.placeholder(dtype=tf.int32, shape=(None,), name='decoder_inputs_length')\n",
    "\n",
    "        # for training we add <s> start tag for the input of the decoder and </s> end tag for the decoder target\n",
    "        # as shown in figure https://www.tensorflow.org/images/basic_seq2seq.png\n",
    "\n",
    "        starttokens = tf.ones([self.batch_size, 1], dtype=tf.int32) * config.DECODER_START_TOKEN_ID\n",
    "        endtokens = tf.ones([self.batch_size, 1], dtype=tf.int32) * config.DECODER_END_TOKEN_ID\n",
    "\n",
    "        self.decoder_inputs_train = tf.concat([starttokens, self.decoder_inputs], axis=1)\n",
    "        self.decoder_targets_train = tf.concat([self.decoder_inputs, endtokens], axis=1)\n",
    "\n",
    "        # decoder_inputs_length_train: [batch_size]\n",
    "        # both input and target to the decoder are of the same length\n",
    "        self.decoder_inputs_length_train = self.decoder_inputs_length + 1\n",
    "        self.decoder_targets_length_train = self.decoder_inputs_length + 1\n",
    "        # calculating max_decoder_length\n",
    "        self.decoder_max_length = tf.reduce_max(self.decoder_inputs_length_train)\n",
    "\n",
    "\n",
    "        # global step\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "\n",
    "    def __build_sample_softmax(self):\n",
    "        \n",
    "        if 0 < config.NUM_SAMPLES < config.DEC_VOCAB:\n",
    "\n",
    "            w = tf.get_variable(\"proj_w\", shape=[config.HIDDEN_SIZE, config.DEC_VOCAB])\n",
    "            b = tf.get_variable(\"proj_b\", shape=[config.DEC_VOCAB])\n",
    "            self.output_projection = (w, b)\n",
    "\n",
    "        def sampled_loss(inputs, labels):\n",
    "            labels = tf.reshape(labels, [-1, 1])\n",
    "            return tf.nn.sampled_softmax_loss(tf.transpose(w), b, inputs, labels,\n",
    "                                              config.NUM_SAMPLES, config.DEC_VOCAB)\n",
    "\n",
    "        self.softmax_loss_function = sampled_loss\n",
    "\n",
    "    def __create_encoder(self):\n",
    "        print('building encoder ...')\n",
    "        start = time.time()\n",
    "\n",
    "        with tf.variable_scope('encoder'):\n",
    "\n",
    "            # Create Embeddings Weights\n",
    "            self.encoder_embeddings = tf.get_variable(\"encoder_embeddings\",\n",
    "                                                      shape=[config.ENC_VOCAB, config.HIDDEN_SIZE],\n",
    "                                                      initializer=self.__helper__initializer(),\n",
    "                                                      dtype=tf.float32\n",
    "                                                      )\n",
    "            # embedding the encoder inputs\n",
    "            encoder_inputs_embedded = tf.nn.embedding_lookup(self.encoder_embeddings, self.encoder_inputs)\n",
    "\n",
    "            # changing the dimensionality of embedded inputs into hidden size\n",
    "            encoder_input_layer = Dense(config.HIDDEN_SIZE, dtype=tf.float32, name='encoder_input_projection')\n",
    "            self.encoder_inputs_embedded = encoder_input_layer(encoder_inputs_embedded)\n",
    "\n",
    "            # create encoder cell\n",
    "            gru = tf.nn.rnn_cell.GRUCell(config.HIDDEN_SIZE)\n",
    "            self.encoder_cell = tf.nn.rnn_cell.MultiRNNCell([gru] * config.NUM_LAYERS)\n",
    "\n",
    "            # Encode input sequences into context vectors:\n",
    "            # encoder_outputs: [batch_size, max_time_step, cell_output_size]\n",
    "            # encoder_state: [batch_size, cell_output_size]\n",
    "            \n",
    "            self.encoder_outputs, self.encoder_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=self.encoder_cell,\n",
    "                inputs=self.encoder_inputs_embedded,\n",
    "                sequence_length=self.encoder_inputs_length,\n",
    "                dtype=tf.float32\n",
    "            )\n",
    "\n",
    "        print('Building encoder in: ', time.time() - start, ' secs')\n",
    "\n",
    "    def __create_decoder(self):\n",
    "        print(\"building decoder and attention ..\")\n",
    "        start = time.time()\n",
    "\n",
    "        with tf.variable_scope('decoder'):\n",
    "\n",
    "            # input and output layers to the decoder\n",
    "            decoder_input_layer = Dense(config.HIDDEN_SIZE, dtype=tf.float32, name='decoder_input_projection')\n",
    "            decoder_output_layer = Dense(config.DEC_VOCAB, name=\"decoder_output_projection\")\n",
    "            self.decoder_initial_state = self.encoder_last_state\n",
    "\n",
    "            # creating decoder embedding weights\n",
    "            self.decoder_embeddings = tf.get_variable(\"decoder_embeddings\",\n",
    "                                                      shape=[config.DEC_VOCAB, config.HIDDEN_SIZE],\n",
    "                                                      initializer=self.__helper__initializer(),\n",
    "                                                      dtype=tf.float32\n",
    "                                                      )\n",
    "\n",
    "            # create decoder cell:\n",
    "            gru = tf.nn.rnn_cell.GRUCell(config.HIDDEN_SIZE)\n",
    "            self.decoder_cell_list = [gru] * config.NUM_LAYERS\n",
    "\n",
    "            self.decoder_cell = tf.nn.rnn_cell.MultiRNNCell(self.decoder_cell_list)\n",
    "\n",
    "            # compose the decoder\n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # changing inputs to embeddings and then through the input projection\n",
    "                # decoder_inputs_embedded: [batch_size, max_time_step + 1, embedding_size]\n",
    "                self.decoder_inputs_embedded = tf.nn.embedding_lookup(params=self.decoder_embeddings, ids=self.decoder_inputs_train)\n",
    "                self.decoder_inputs_embedded = decoder_input_layer(self.decoder_inputs_embedded)\n",
    "\n",
    "                # Helper to feed inputs to the training:\n",
    "\n",
    "                self.training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=self.decoder_inputs_embedded,\n",
    "                    sequence_length=self.decoder_inputs_length_train,\n",
    "                    name='training_helper')\n",
    "\n",
    "                # self.decoder_initial_state = [state for state in self.encoder_last_state]\n",
    "                # self.decoder_initial_state[-1] = self.decoder_cell_list[-1].zero_state(batch_size=tf.shape(self.encoder_inputs)[0], dtype=tf.float32)\n",
    "                self.decoder_initial_state = self.encoder_last_state\n",
    "\n",
    "                # Build the decoder\n",
    "                self.decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=self.decoder_cell,\n",
    "                    helper=self.training_helper,\n",
    "                    initial_state=self.decoder_initial_state,\n",
    "                    output_layer=decoder_output_layer)\n",
    "\n",
    "                self.decoder_outputs, self.decoder_last_state, self.decoder_outputs_length_decode = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder=self.decoder,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=self.decoder_max_length\n",
    "                )\n",
    "\n",
    "        print('Building decoder in: ', time.time() - start, ' secs')\n",
    "\n",
    "    def __create_loss(self):\n",
    "\n",
    "        print('Creating loss...')\n",
    "        start = time.time()\n",
    "\n",
    "        self.decoder_logits = tf.identity(self.decoder_outputs.rnn_output, name=\"decoder_logits\")\n",
    "        self.decoder_pred = tf.argmax(self.decoder_logits, axis=-1, name=\"decoder_pred\")\n",
    "\n",
    "        # masking the sequence in order to calculate the error according to the calculated\n",
    "        mask = tf.sequence_mask(self.decoder_inputs_length_train, maxlen=self.decoder_max_length, dtype=tf.float32, name=\"masks\")\n",
    "\n",
    "        # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "        self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.decoder_logits,\n",
    "                                         targets=self.decoder_targets_train,\n",
    "                                         average_across_timesteps=True,\n",
    "                                         average_across_batch=True,\n",
    "                                         weights=mask,\n",
    "                                         name=\"batch_loss\")\n",
    "\n",
    "        print('Building loss in: ', time.time() - start, ' secs')\n",
    "\n",
    "\n",
    "    def __create_optimizer(self):\n",
    "        print('creating optimizer...')\n",
    "        start = time.time()\n",
    "\n",
    "        self.opt = tf.train.RMSPropOptimizer(learning_rate=config.LR)\n",
    "\n",
    "        # normalize the gradients of a parameter vector when its L2 norm exceeds a certain threshold according to\n",
    "        trainable_params = tf.trainable_variables()\n",
    "        \n",
    "        # calculate gradients of the loss given all the trainable parameters\n",
    "        gradients = tf.gradients(self.loss, trainable_params)\n",
    "        \n",
    "        # Gradient clipping\n",
    "        # new_gradients = gradients * threshold / l2_norm(gradients)\n",
    "        clip_gradients, _ = tf.clip_by_global_norm(gradients, config.MAX_GRAD_NORM)\n",
    "\n",
    "        self.updates = self.opt.apply_gradients(zip(clip_gradients, trainable_params), global_step=self.global_step)\n",
    "\n",
    "\n",
    "        print('Building optimizer in: ', time.time() - start, ' secs')\n",
    "\n",
    "\n",
    "    def __helper__initializer(self):\n",
    "        sqrt3 = math.sqrt(3)  # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "        initializer = tf.random_uniform_initializer(-sqrt3, sqrt3, dtype=tf.float32)\n",
    "        return initializer\n",
    "\n",
    "    def train(self, sess,encoder_inputs, encoder_inputs_length, decoder_inputs, decoder_inputs_lengths):\n",
    "\n",
    "        feed_dict = {\n",
    "            self.encoder_inputs: encoder_inputs,\n",
    "            self.encoder_inputs_length: encoder_inputs_length,\n",
    "            self.decoder_inputs: decoder_inputs,\n",
    "            self.decoder_inputs_length: decoder_inputs_lengths\n",
    "        }\n",
    "        _, loss = sess.run([self.updates, self.loss], feed_dict=feed_dict)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new seq 2 seq model\n",
      "building encoder ...\n",
      "Building encoder in:  0.166300773621  secs\n",
      "building decoder and attention ..\n",
      "Building decoder in:  1.03757119179  secs\n",
      "Creating loss...\n",
      "Building loss in:  0.0138518810272  secs\n",
      "creating optimizer...\n",
      "Building optimizer in:  1.06437301636  secs\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.80885\n",
      "6.74696\n",
      "6.68086\n",
      "6.60276\n",
      "6.49979\n",
      "6.34733\n",
      "6.11445\n",
      "5.97212\n",
      "6.10463\n",
      "5.60023\n",
      "5.66922\n",
      "6.5992\n",
      "6.21638\n",
      "5.85056\n",
      "5.34537\n",
      "5.25792\n",
      "5.22079\n",
      "5.70348\n",
      "7.3468\n",
      "6.12712\n",
      "5.69715\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cd24bcc87595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-716a2b857aa3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, encoder_inputs, encoder_inputs_length, decoder_inputs, decoder_inputs_lengths)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_inputs_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecoder_inputs_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         }\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "encoder_lengths = [5, 8, 8, 5, 10] * 100\n",
    "decoder_lengths = [5, 8, 8, 5, 10] * 100\n",
    "\n",
    "encoder_inputs = np.zeros((500,10))\n",
    "\n",
    "for c, i in enumerate(encoder_lengths):\n",
    "    encoder_inputs[c,:i] = np.random.randint(0, 300, i)\n",
    "\n",
    "decoder_inputs = np.zeros_like(encoder_inputs)\n",
    "\n",
    "for c, r in enumerate(encoder_inputs):\n",
    "    tmp = deque(r)\n",
    "    tmp.rotate(1)\n",
    "    tmp1 = tmp\n",
    "    tmp.rotate(1)\n",
    "    tmp2 = tmp\n",
    "    tmp.rotate(1)\n",
    "    tmp3 = tmp\n",
    "    decoder_inputs[c] = np.sum([tmp1, tmp2, tmp3], axis=0)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    encoder_inputs = np.array(encoder_inputs)\n",
    "    encoder_lengths = np.array(encoder_lengths)\n",
    "    decoder_inputs = np.array(decoder_inputs)\n",
    "    decoder_lengths = np.array(decoder_lengths)\n",
    "\n",
    "\n",
    "    EPOCHS = 100\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        loss = model.train(sess, encoder_inputs, encoder_lengths, decoder_inputs, decoder_lengths)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}